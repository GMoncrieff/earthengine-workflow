main:
  steps:
  - init:
      assign:
        - project: "test-ee-deploy"
        - region: "us-central1"
        - bucket_name: "test-bucket-ee-deploy"
        - model: "gs://ee-model-fortest"
        - job_name: "ee-test-workflow-job"
        - template_path: "gs://ee-model-dataflow-test/samples/dataflow/templates/eetest-beam-run.json"
        - machine: "e2-standard-2"
        - max_workers: "20"
        - datatest: "gs://test-bucket-ee-deploy/2022-11-09"

  #gee download cloud function
  #dataflow
  - predict_dataflow:
      call: LaunchDataflow
      args:
        project: ${project}
        region: ${region}
        template: ${template_path}
        data_dir: ${datatest}
        model_dir: ${model}
        machine: ${machine}
        workers: ${max_workers}
      result: JobId

  #check on dataflow status
  - wait_dataflow:
      call: DataflowWaitUntilStatus
      args:
        project: ${project}
        region: ${region}
        jobId: ${JobId}
        status: "JOB_STATE_DONE"

LaunchDataflow:
  params: [project, region, template, data_dir, model_dir, workers, machine]
  steps:
    - log:
        call: sys.log
        args:
          text: ${"dataflow output:" + " " + data_dir + "/predict/"}
          severity: "INFO"
            
    - launch:
        call: http.post
        args:
          url: ${"https://dataflow.googleapis.com/v1b3/projects/"+project+"/locations/"+region+"/flexTemplates:launch"}
          auth:
            type: OAuth2
          body:
            launchParameter:
              jobName: ${"workflowlunach"}
              containerSpecGcsPath: ${template}
              parameters: 
                input: ${"'"+data_dir + "/download/*.tfrecord.gz"+"'"}
                output: ${"'"+data_dir + "/predict/"+"'"}
                model: ${"'"+model_dir+"'"}
                max_num_workers: ${"'"+workers+"'"}
                worker_machine_type: ${"'"+machine+"'"}
              
        result: dataflowResponse
        next: jobCreated
    - jobCreated:
        return: ${dataflowResponse.body.job.id}



DataflowWaitUntilStatus:
  params: [project, region, jobId, status]
  steps:
    - init:
        assign:
          - currentStatus: ""
          - failureStatuses: ["JOB_STATE_FAILED", "JOB_STATE_CANCELLED", "JOB_STATE_UPDATED", "JOB_STATE_DRAINED"]
    - check_condition:
        switch:
          - condition: ${currentStatus in failureStatuses}
            next: exit_fail
          - condition: ${currentStatus != status}
            next: iterate
        next: exit_success
    - iterate:
        steps:
          - sleep30s:
              call: sys.sleep
              args:
                seconds: 30
          - getJob:
              call: http.get
              args:
                url: ${"https://dataflow.googleapis.com/v1b3/projects/"+project+"/locations/"+region+"/jobs/"+jobId}
                auth:
                  type: OAuth2
              result: getJobResponse
          - getStatus:
              assign:
                - currentStatus: ${getJobResponse.body.currentState}
          - log:
              call: sys.log
              args:
                text: ${"Current job status="+currentStatus}
                severity: "INFO"
        next: check_condition
    - exit_success:
        return: ${currentStatus}
    - exit_fail:
        raise: ${"Dataflow job in unexpected terminal status "+currentStatus}

